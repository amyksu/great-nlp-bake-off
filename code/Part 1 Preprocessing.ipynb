{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose \n",
    "\n",
    "The purpose of this notebook is to read in subtitle data in vtt format and create dataframes from the text based on episode, speaker and sentence.\n",
    "\n",
    "##  Read in libraries and data\n",
    "\n",
    "Using the webvtt python library, I will read in all of the subtitle files that I obtained from Netflix. I will then strip just the text from the vtt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:27.709096Z",
     "start_time": "2019-05-21T22:01:27.013680Z"
    }
   },
   "outputs": [],
   "source": [
    "import webvtt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:28.364908Z",
     "start_time": "2019-05-21T22:01:28.356191Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a list of episode numbers\n",
    "episodes = ['0101', '0102', '0103', '0104','0105','0106','0107','0108','0109','0110',\n",
    "            '0201', '0202', '0203', '0204','0205','0206','0207','0208','0209','0210',\n",
    "           '0301', '0302', '0303', '0304','0305','0306','0307','0308','0309','0310',\n",
    "           '0401', '0402', '0403', '0404','0405','0406','0407','0408','0409','0410',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:32.862083Z",
     "start_time": "2019-05-21T22:01:29.613479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list of dictionaries by episode and text \n",
    "data = []\n",
    "\n",
    "for e in episodes:\n",
    "    episode = {}\n",
    "    episode['episode_num'] = e\n",
    "    episode['season'] = e[:2]\n",
    "    episode['episode'] = e[2:]\n",
    "    vtt = webvtt.read('gbbo_{}.vtt'.format(e))\n",
    "    episode['text'] = \" \".join([ele.text for ele in vtt])\n",
    "    data.append(episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read into DataFrame\n",
    "\n",
    "Now that I have all of the text, I will now read all of the episodes into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:34.635811Z",
     "start_time": "2019-05-21T22:01:34.583208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_num</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0406</td>\n",
       "      <td>04</td>\n",
       "      <td>06</td>\n",
       "      <td>It's week six, and we feel like Snow White bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0407</td>\n",
       "      <td>04</td>\n",
       "      <td>07</td>\n",
       "      <td>[man] Support from viewers like you makes this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0408</td>\n",
       "      <td>04</td>\n",
       "      <td>08</td>\n",
       "      <td>We've gone historical. I'm talking Henry VIII,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0409</td>\n",
       "      <td>04</td>\n",
       "      <td>09</td>\n",
       "      <td>[announcer]\\nSupport from viewers like you\\nma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0410</td>\n",
       "      <td>04</td>\n",
       "      <td>10</td>\n",
       "      <td>[Sue] In the beginning... [Paul] Gorgeous, gor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_num season episode  \\\n",
       "35        0406     04      06   \n",
       "36        0407     04      07   \n",
       "37        0408     04      08   \n",
       "38        0409     04      09   \n",
       "39        0410     04      10   \n",
       "\n",
       "                                                 text  \n",
       "35  It's week six, and we feel like Snow White bec...  \n",
       "36  [man] Support from viewers like you makes this...  \n",
       "37  We've gone historical. I'm talking Henry VIII,...  \n",
       "38  [announcer]\\nSupport from viewers like you\\nma...  \n",
       "39  [Sue] In the beginning... [Paul] Gorgeous, gor...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['episode_num','season','episode','text']\n",
    "\n",
    "df = pd.DataFrame(data, columns = cols)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate by Speaker \n",
    "\n",
    "Now that I have all of the text from each episode, I will now separate each episode into individual dialogue by speaker. There are a couple of challenges in separating the speaker from the dialogue. \n",
    "\n",
    "First, speakers are identified and separated from dialogue in two ways:\n",
    "\n",
    "  * A colon ( : )\n",
    "   \n",
    "  * Square brackets ( [ ] )\n",
    "\n",
    "Second, there are two ways speakers' names are formatted:\n",
    "   * All capital letters \n",
    "   \n",
    "   * Regular capitalization\n",
    "\n",
    "Third, when a speaker is off camera, their dialogue is noted as a voiceover and is added as part of the speaker's name. For example, \"Mary\" would then become \"Mary, voice-over\" or \"Mary voice-over\".  \n",
    "\n",
    "\n",
    "To address all of these challenges, I will first use RegEx to find all character names before a colon or within square brackets. Then, I will replace all the voice over text with \"vo\" to more easily identify these cases. Then, I will count the amount of colons and square brackets to identify which separation method was used in the episode. Depending on which case it is, the for loop will reference the RegEx statements I created and extract the names and separate the names from the dialogue.\n",
    "\n",
    "In addition to all of the different cases, the speakers themselves are cased in different ways. Some episodes' dialogue are all capitalized, while other episodes have dialogue with regular capitalization. To address this issue, I created a counter that will count the amount of capitalized letters. Within my colon/bracket if statement, I will use another if statement that will identify which case to use for separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:37.703738Z",
     "start_time": "2019-05-21T22:01:37.699785Z"
    }
   },
   "outputs": [],
   "source": [
    "# RegEx \n",
    "## to get everything between square brackets: r'[[].*?[]]'\n",
    "## to get everything that starts with a capital letter: r'[[][A-Z].*?[]]''\n",
    "## to get everything that starts with a capital letter and no white space: r'[[][A-Z][a-z]*?[]]'\n",
    "\n",
    "regex_person_reg = r\"([A-Z][a-z].*?[^\\s]*)\\:\"\n",
    "regex_person_upper = r\"([A-Z][^\\s]*)\\:\"\n",
    "regex_parens = r'[[][A-Z].*?[]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:39.119748Z",
     "start_time": "2019-05-21T22:01:38.836373Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyksu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: FutureWarning: Possible nested set at position 1\n",
      "/Users/amyksu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: FutureWarning: Possible nested set at position 1\n"
     ]
    }
   ],
   "source": [
    "# Iterate through text in rows and split out dialogue from speaker \n",
    "final = []\n",
    "\n",
    "for ix, row in df.iterrows():\n",
    "    text = row['text'].replace(', voice-over',\" vo\")\n",
    "    text = row['text'].replace('voice-over',\"Vo\")\n",
    "    \n",
    "    # count how many colons and brackets to determine which case to use \n",
    "    c = text.count(':')\n",
    "    p = text.count('[')\n",
    "    if c > p:\n",
    "        \n",
    "        # count how many upper case and lower case to determine which case to use \n",
    "        count_upper = 0\n",
    "        count_lower = 0\n",
    "        for t in row['text']:\n",
    "            if t.isupper():\n",
    "                count_upper += 1\n",
    "            else:\n",
    "                count_lower += 1\n",
    "        \n",
    "        if count_upper > count_lower:\n",
    "            matches = re.findall(regex_person_reg, text, re.MULTILINE)\n",
    "    \n",
    "            characters = []\n",
    "            for match in matches:\n",
    "                characters.append(match)\n",
    "        \n",
    "            replaced_text = re.sub(regex_person_reg, '|||||||', text)\n",
    "            split_text = replaced_text.split('|||||||')\n",
    "            \n",
    "            if len(characters) < len(split_text):\n",
    "                final.append(pd.DataFrame({'episode_num':row['episode_num'], 'season':row['season']\n",
    "                                       , 'episode':row['episode'],'character':characters, 'dialogue':split_text[1:]}))\n",
    "            else:\n",
    "                final.append(pd.DataFrame({'episode_num':row['episode_num'], 'season':row['season']\n",
    "                                       , 'episode':row['episode'], 'character':characters, 'dialogue':split_text}))\n",
    "        else:\n",
    "            matches = re.findall(regex_person_upper, text, re.MULTILINE)\n",
    "        \n",
    "            characters = []\n",
    "        \n",
    "            for match in matches:\n",
    "                characters.append(match)\n",
    "        \n",
    "            replaced_text = re.sub(regex_person_upper, '|||||||', text)\n",
    "            split_text = replaced_text.split('|||||||')\n",
    "            \n",
    "            if len(characters) < len(split_text):\n",
    "                final.append(pd.DataFrame({'episode_num':row['episode_num'], 'season':row['season']\n",
    "                                           , 'episode':row['episode'],'character':characters, 'dialogue':split_text[1:]}))\n",
    "            else:\n",
    "                final.append(pd.DataFrame({'episode_num':row['episode_num'], 'season':row['season']\n",
    "                                           , 'episode':row['episode'], 'character':characters, 'dialogue':split_text}))\n",
    "    else:\n",
    "        matches = re.findall(regex_parens, text, re.MULTILINE)\n",
    "        \n",
    "        characters = []\n",
    "        \n",
    "        for match in matches:\n",
    "            characters.append(match)\n",
    "        \n",
    "        replaced_text = re.sub(regex_parens, '|||||||', text)\n",
    "        split_text = replaced_text.split('|||||||')\n",
    "        \n",
    "        if len(characters) < len(split_text):\n",
    "            final.append(pd.DataFrame({'episode_num':row['episode_num'], 'season':row['season'], 'episode':row['episode'],'character':characters, 'dialogue':split_text[1:]}))\n",
    "        else:\n",
    "            final.append(pd.DataFrame({'episode_num':row['episode_num'], 'season':row['season'], 'episode':row['episode'], 'character':characters, 'dialogue':split_text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split out everyone from what they are saying, I will concatenate all of these episodes together into one big dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:44.198252Z",
     "start_time": "2019-05-21T22:01:44.181584Z"
    }
   },
   "outputs": [],
   "source": [
    "full = pd.concat(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:49.088524Z",
     "start_time": "2019-05-21T22:01:49.076978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_num</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Announcer</td>\n",
       "      <td>HELP EVERYONE EXPLORE NEW WORLDS AND IDEAS. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Mel</td>\n",
       "      <td>THOUSANDS OF PEOPLE APPLIED. IT'S BEEN QUITE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Mel</td>\n",
       "      <td>JUST 12 HAVE MADE IT THROUGH, AND OVER THE NE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Mel</td>\n",
       "      <td>THEIR BAKING WILL BE SCRUTINIZED, WHATEVER TH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Woman</td>\n",
       "      <td>I'VE BEEN BAKING FOR 60 YEARS. I SUPPOSE I'M ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode_num season episode  character  \\\n",
       "0        0101     01      01  Announcer   \n",
       "1        0101     01      01        Mel   \n",
       "2        0101     01      01        Mel   \n",
       "3        0101     01      01        Mel   \n",
       "4        0101     01      01      Woman   \n",
       "\n",
       "                                            dialogue  \n",
       "0   HELP EVERYONE EXPLORE NEW WORLDS AND IDEAS. S...  \n",
       "1   THOUSANDS OF PEOPLE APPLIED. IT'S BEEN QUITE ...  \n",
       "2   JUST 12 HAVE MADE IT THROUGH, AND OVER THE NE...  \n",
       "3   THEIR BAKING WILL BE SCRUTINIZED, WHATEVER TH...  \n",
       "4   I'VE BEEN BAKING FOR 60 YEARS. I SUPPOSE I'M ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.index = pd.RangeIndex(len(full.index))\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:01:54.433442Z",
     "start_time": "2019-05-21T22:01:54.418411Z"
    }
   },
   "outputs": [],
   "source": [
    "full['dialogue'] = full['dialogue'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:03:27.427037Z",
     "start_time": "2019-05-21T22:03:27.410863Z"
    }
   },
   "outputs": [],
   "source": [
    "pbs = full[full['dialogue'].str.contains('support your pbs station')].index\n",
    "full.drop(index=pbs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my dataframe, I will now clean up any edge cases as well as consolidate the names by formatting all names the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T15:56:01.836236Z",
     "start_time": "2019-05-19T15:56:01.826076Z"
    }
   },
   "outputs": [],
   "source": [
    "# All unique characters \n",
    "full['character'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also remove any blank dialogue that I might have captured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:03:34.941849Z",
     "start_time": "2019-05-21T22:03:34.877462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace empty cells with na\n",
    "full = full.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:03:40.140861Z",
     "start_time": "2019-05-21T22:03:40.130831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Retained:99.85 %\n"
     ]
    }
   ],
   "source": [
    "#Drop rows with no dialogue\n",
    "total_rows = len(full.index)\n",
    "\n",
    "# Drop na's \n",
    "full.dropna(subset=['dialogue'],inplace=True)\n",
    "data_kept = len(full.index)/total_rows\n",
    "print('Data Retained:'+str(round(data_kept*100,2))+' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple cases where the formatting was different. I will edit these individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:03:45.746980Z",
     "start_time": "2019-05-21T22:03:45.722734Z"
    }
   },
   "outputs": [],
   "source": [
    "# dialogue was separatd by semi colon\n",
    "full[full['character']=='Sue; OK, THAT\\'S IT, THE BAKE\\'S OVER. BAKERS, STEP AWAY FROM YOUR ENTREMETS, S\\'IL VOUS PLAIT. OH... ALL OF IT WENT... [SHEEP BLEATING] IT TAKES A LOT OF GUTS TO BE ABLE TO SHOW ALL THE LAYERS. Richard'] = full[full['character']=='Sue; OK, THAT\\'S IT, THE BAKE\\'S OVER. BAKERS, STEP AWAY FROM YOUR ENTREMETS, S\\'IL VOUS PLAIT. OH... ALL OF IT WENT... [SHEEP BLEATING] IT TAKES A LOT OF GUTS TO BE ABLE TO SHOW ALL THE LAYERS. Richard'].replace('Sue; OK, THAT\\'S IT, THE BAKE\\'S OVER. BAKERS, STEP AWAY FROM YOUR ENTREMETS, S\\'IL VOUS PLAIT. OH... ALL OF IT WENT... [SHEEP BLEATING] IT TAKES A LOT OF GUTS TO BE ABLE TO SHOW ALL THE LAYERS. Richard', 'Richard')\n",
    "\n",
    "# dialogue separatd by colon and bracket\n",
    "full[full['character']=='Whispering] YOU\\'RE KIDDING! Paul'] = full[full['character']=='Whispering] YOU\\'RE KIDDING! Paul'].replace('Whispering] YOU\\'RE KIDDING! Paul', 'Paul')\n",
    "\n",
    "# Paul Hollywood referred to as Paul H.\n",
    "full[full['character']=='H.'] = full[full['character']=='H.'].replace('H.', 'Paul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now remove all of the punctuation and lower case the characters and the dialogue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:03:52.416407Z",
     "start_time": "2019-05-21T22:03:52.339506Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Remove punctuation and lower case character names \n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "full['character'] = full['character'].map(punc_lower)\n",
    "full['character'] = [character.strip() for character in full['character']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are a number of typos and combination of characters who speak together, I will fix and identify these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:03:57.701861Z",
     "start_time": "2019-05-21T22:03:57.659550Z"
    }
   },
   "outputs": [],
   "source": [
    "full[full['character']=='paul and mary'] = full[full['character']=='paul and mary'].replace('paul and mary', 'judges')\n",
    "full[full['character']=='sue and mel'] = full[full['character']=='sue and mel'].replace('sue and mel', 'both')\n",
    "full[full['character']=='sure'] = full[full['character']=='sure'].replace('sure', 'sue')\n",
    "full[full['character']=='different man'] = full[full['character']=='different man'].replace('different man', 'man')\n",
    "full[full['character']=='pual'] = full[full['character']=='pual'].replace('pual', 'paul')\n",
    "full[full['character']=='mary  paul  and mel'] = full[full['character']=='mary  paul  and mel'].replace('mary  paul  and mel', 'judges')\n",
    "full[full['character']=='hollywood'] = full[full['character']=='hollywood'].replace('hollywood', 'paul')\n",
    "full[full['character']=='paul and sue'] = full[full['character']=='paul and sue'].replace('paul and sue', 'sue')\n",
    "full[full['character']=='narration'] = full[full['character']=='narration'].replace('narration', 'narrator')\n",
    "full[full['character']=='french accent'] = full[full['character']=='french accent'].replace('french accent', 'sue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T16:03:51.374551Z",
     "start_time": "2019-05-19T16:03:51.363802Z"
    }
   },
   "outputs": [],
   "source": [
    "full['character'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now strip all of the action verbs next to some of the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:05.864383Z",
     "start_time": "2019-05-21T22:04:05.838122Z"
    }
   },
   "outputs": [],
   "source": [
    "name = full['character'].str.split(' ', n=1, expand = True)\n",
    "full['character'] = name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:10.881123Z",
     "start_time": "2019-05-21T22:04:10.860404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(full['character'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T15:09:43.461862Z",
     "start_time": "2019-05-19T15:09:43.447286Z"
    }
   },
   "source": [
    "Now that I have cleaned all of the names, I will create a column with each person's role in the show (judge, commentator, contestant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:24.384379Z",
     "start_time": "2019-05-21T22:04:24.374743Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to assign character roles \n",
    "def roles(row):\n",
    "    if row['character'] == 'paul' or row['character'] == 'mary' or row['character'] =='judges':\n",
    "        return 'judge'\n",
    "    elif row['character'] == 'sue' or row['character'] == 'mel' or row['character'] == 'both' or row['character'] == 'announcer' or row['character'] == 'narrator':\n",
    "        return 'host'\n",
    "    else:\n",
    "        return 'contestant'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:30.111802Z",
     "start_time": "2019-05-21T22:04:29.813655Z"
    }
   },
   "outputs": [],
   "source": [
    "full['role'] = full.apply(roles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:35.422354Z",
     "start_time": "2019-05-21T22:04:35.401657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_num</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>mel</td>\n",
       "      <td>thousands of people applied. it's been quite ...</td>\n",
       "      <td>host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>mel</td>\n",
       "      <td>just 12 have made it through, and over the ne...</td>\n",
       "      <td>host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>mel</td>\n",
       "      <td>their baking will be scrutinized, whatever th...</td>\n",
       "      <td>host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>woman</td>\n",
       "      <td>i've been baking for 60 years. i suppose i'm ...</td>\n",
       "      <td>contestant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0101</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>man</td>\n",
       "      <td>the thing that worries me the most is probabl...</td>\n",
       "      <td>contestant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode_num season episode character  \\\n",
       "1        0101     01      01       mel   \n",
       "2        0101     01      01       mel   \n",
       "3        0101     01      01       mel   \n",
       "4        0101     01      01     woman   \n",
       "5        0101     01      01       man   \n",
       "\n",
       "                                            dialogue        role  \n",
       "1   thousands of people applied. it's been quite ...        host  \n",
       "2   just 12 have made it through, and over the ne...        host  \n",
       "3   their baking will be scrutinized, whatever th...        host  \n",
       "4   i've been baking for 60 years. i suppose i'm ...  contestant  \n",
       "5   the thing that worries me the most is probabl...  contestant  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to identifying the characters' roles in the show, for my project's purpose. I would like to distinguish between male and female characters. I will do this by creating a list of all of the unique character names, and creating a dictionary that will map out whether the character is female or male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T19:25:59.062797Z",
     "start_time": "2019-05-19T19:25:59.054231Z"
    }
   },
   "outputs": [],
   "source": [
    "full.character.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:40.213554Z",
     "start_time": "2019-05-21T22:04:40.204126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary with gender identification\n",
    "mapping = {'announcer':'male',\n",
    " 'mel':'female',\n",
    " 'woman':'female',\n",
    " 'man':'male',\n",
    " 'sue':'female',\n",
    " 'mary':'female',\n",
    " 'paul':'male',\n",
    " 'diana':'female',\n",
    " 'chetna':'female',\n",
    " 'claire':'female',\n",
    " 'richard':'male',\n",
    " 'jordan':'male',\n",
    " 'enwezor':'male',\n",
    " 'children':'both',\n",
    " 'kate':'female',\n",
    " 'martha':'female',\n",
    " 'iain':'male',\n",
    " 'nancy':'female',\n",
    " 'luis':'male',\n",
    " 'both':'female',\n",
    " 'judges':'both',\n",
    " 'norman':'male',\n",
    " 'narrator':'male',\n",
    " 'all':'both',\n",
    " 'peter':'male',\n",
    " 'sarah':'female',\n",
    " 'tim':'male',\n",
    " 'girl':'female',\n",
    " 'louise':'female',\n",
    " 'glenn':'male',\n",
    " 'ali':'male',\n",
    " 'lucy':'female',\n",
    " 'howard':'male',\n",
    " 'frances':'female',\n",
    " 'mark':'male',\n",
    " 'ruby':'female',\n",
    " 'christine':'female',\n",
    " 'robert':'male',\n",
    " 'toby':'male',\n",
    " 'deborah':'female',\n",
    " 'beca':'female',\n",
    " 'kimberley':'female',\n",
    " 'meg':'female',\n",
    " 'rob':'male',\n",
    " 'kimberly':'female',\n",
    " 'deirdre':'female',\n",
    " 'kevin':'male',\n",
    " 'natalie':'female',\n",
    " 'giuseppe':'male',\n",
    " 'marie':'female',\n",
    " 'nadiya':'female',\n",
    " 'stu':'male',\n",
    " 'ian':'male',\n",
    " 'sandy':'female',\n",
    " 'ugne':'female',\n",
    " 'dorret':'female',\n",
    " 'flora':'female',\n",
    " 'tamal':'male',\n",
    " 'mat':'male',\n",
    " 'alvin':'male',\n",
    " 'jagger':'male',\n",
    " 'abdal':'male',\n",
    " 'shoma':'female',\n",
    " 'candice':'female',\n",
    " 'andrew':'male',\n",
    " 'val':'female',\n",
    " 'benjamina':'female',\n",
    " 'michael':'male',\n",
    " 'tom':'male',\n",
    " 'rav':'male',\n",
    " 'jane':'female',\n",
    " 'selasi':'male',\n",
    " 'helen':'female',\n",
    " 'kay':'female',\n",
    " 'nigel':'male',\n",
    " 'amy':'female',\n",
    " 'henry':'male'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:44.960013Z",
     "start_time": "2019-05-21T22:04:44.950830Z"
    }
   },
   "outputs": [],
   "source": [
    "full['gender'] = full['character'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:04:55.480989Z",
     "start_time": "2019-05-21T22:04:55.420457Z"
    }
   },
   "outputs": [],
   "source": [
    "full.replace({'\\n': ' '}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T19:26:14.033755Z",
     "start_time": "2019-05-19T19:26:14.013973Z"
    }
   },
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will save the final cleaned and separated data into a csv file for the next process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T22:05:06.673916Z",
     "start_time": "2019-05-21T22:05:06.576941Z"
    }
   },
   "outputs": [],
   "source": [
    "full.to_csv('clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
